"""
Sistema RAG Completo - IntegraÃ§Ã£o de Todos os MÃ³dulos
Arquivo principal que orquestra todo o pipeline RAG
"""

import time
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

from loguru import logger

# Importar todos os mÃ³dulos
import sys
sys.path.append(str(Path(__file__).parent))

try:
    from index.main import IndexManager
    from lexical_vector.main import HybridSearcher
    from rerank.main import Reranker
    from llm.main import LLMManager
    from grounding.main import GroundingValidator
    
    # Imports alternativos para mÃ³dulos com hÃ­fens
    import importlib
    post_processing_module = importlib.import_module('post-processing.main')
    ResponseFormatter = post_processing_module.ResponseFormatter
    OutputFormat = post_processing_module.OutputFormat
    
    telemetry_module = importlib.import_module('telemetry-learning.main')
    TelemetryCollector = telemetry_module.TelemetryCollector
    FeedbackType = telemetry_module.FeedbackType  
    LearningEngine = telemetry_module.LearningEngine
    
    from config import config, setup_directories
except ImportError as e:
    print(f"Erro ao importar mÃ³dulos: {e}")
    print("Verifique se todas as dependÃªncias estÃ£o instaladas")
    sys.exit(1)


@dataclass 
class RAGResponse:
    """Resposta completa do sistema RAG"""
    answer: str
    sources: List[Dict[str, Any]]
    confidence_score: float
    response_time_ms: float
    is_grounded: bool
    query_id: str
    metadata: Dict[str, Any]


class RAGSystem:
    """Sistema RAG completo"""
    
    def __init__(self, enable_telemetry: bool = True):
        """
        Inicializa o sistema RAG
        
        Args:
            enable_telemetry: Se deve habilitar coleta de telemetria
        """
        setup_directories()
        
        self.enable_telemetry = enable_telemetry
        
        # Inicializar componentes
        logger.info("Inicializando sistema RAG...")
        
        try:
            self.index_manager = IndexManager()
            self.searcher = HybridSearcher()
            self.reranker = Reranker()
            self.llm_manager = LLMManager()
            self.grounding_validator = GroundingValidator()
            self.response_formatter = ResponseFormatter()
            
            if self.enable_telemetry:
                self.telemetry_collector = TelemetryCollector()
                self.learning_engine = LearningEngine()
            else:
                self.telemetry_collector = None
                self.learning_engine = None
            
            logger.info("âœ… Sistema RAG inicializado com sucesso")
            
        except Exception as e:
            logger.error(f"âŒ Erro ao inicializar sistema RAG: {e}")
            raise
    
    def index_documents(self, json_path: str) -> bool:
        """
        Indexa documentos de um arquivo JSON
        
        Args:
            json_path: Caminho para arquivo JSON com documentos
            
        Returns:
            True se bem-sucedido
        """
        logger.info(f"Indexando documentos de {json_path}")
        start_time = time.time()
        
        try:
            success = self.index_manager.build_indices_from_json(json_path)
            
            if success:
                # Treinar BM25 do reranker com documentos indexados
                documents = self.index_manager.ingestion.get_all_documents()
                self.reranker.fit_bm25(documents)
                
                elapsed_time = (time.time() - start_time) * 1000
                logger.info(f"âœ… IndexaÃ§Ã£o completa em {elapsed_time:.0f}ms")
                
                return True
            else:
                logger.error("âŒ Falha na indexaÃ§Ã£o")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Erro durante indexaÃ§Ã£o: {e}")
            return False
    
    def query(
        self, 
        question: str,
        top_k: int = None,
        output_format: OutputFormat = OutputFormat.MARKDOWN,
        include_sources: bool = True,
        provider: str = None
    ) -> RAGResponse:
        """
        Executa query completa no sistema RAG
        
        Args:
            question: Pergunta do usuÃ¡rio
            top_k: NÃºmero mÃ¡ximo de resultados
            output_format: Formato de saÃ­da
            include_sources: Se deve incluir fontes
            provider: Provedor LLM especÃ­fico
            
        Returns:
            RAGResponse completa
        """
        start_time = time.time()
        query_id = None
        
        if top_k is None:
            top_k = config.TOP_K_FINAL
        
        try:
            logger.info(f"ðŸ” Processando query: '{question}'")
            
            # 1. Telemetria: Iniciar sessÃ£o se necessÃ¡rio
            if self.telemetry_collector and not self.telemetry_collector.current_session_id:
                self.telemetry_collector.start_session()
            
            # 2. Busca hÃ­brida (lÃ©xica + vetorial)
            logger.info("ðŸ“š Executando busca hÃ­brida...")
            search_results = self.searcher.search(question, top_k=top_k * 2)  # Buscar mais para rerank
            
            if not search_results:
                logger.warning("âš ï¸ Nenhum resultado encontrado na busca")
                return self._create_empty_response(question, start_time)
            
            logger.info(f"ðŸ“Š Encontrados {len(search_results)} resultados iniciais")
            
            # 3. Reranking
            logger.info("ðŸ”„ Aplicando reranking...")
            reranked_results = self.reranker.rerank(question, search_results, top_k=top_k)
            
            if not reranked_results:
                logger.warning("âš ï¸ Nenhum resultado apÃ³s reranking")
                return self._create_empty_response(question, start_time)
            
            logger.info(f"ðŸ“ˆ {len(reranked_results)} resultados apÃ³s reranking")
            
            # 4. Preparar contexto para LLM
            context_passages = []
            for result in reranked_results:
                context_passages.append({
                    'title': result.title,
                    'content': result.content,
                    'id': result.doc_id
                })
            
            # 5. Gerar resposta com LLM
            logger.info("ðŸ¤– Gerando resposta com LLM...")
            rag_prompt = self.llm_manager.create_rag_prompt(question, context_passages)
            
            llm_start = time.time()
            llm_response = self.llm_manager.generate_answer(rag_prompt, provider=provider)
            llm_time = (time.time() - llm_start) * 1000
            
            logger.info(f"ðŸ’¬ Resposta gerada em {llm_time:.0f}ms")
            
            # 6. ValidaÃ§Ã£o de grounding
            logger.info("ðŸ” Validando grounding...")
            grounding_result = self.grounding_validator.validate_grounding(
                llm_response.content, context_passages
            )
            
            # 7. PÃ³s-processamento
            logger.info("âœ¨ Aplicando pÃ³s-processamento...")
            processed_response = self.response_formatter.format_response(
                llm_response.content,
                grounding_result=grounding_result,
                format_type=output_format,
                include_sources=include_sources
            )
            
            # 8. Telemetria: Log da query
            if self.telemetry_collector:
                response_time = (time.time() - start_time) * 1000
                query_id = self.telemetry_collector.log_query(
                    question, 
                    [{'id': r.doc_id, 'title': r.title, 'score': r.final_score} for r in reranked_results],
                    response_time,
                    {
                        'llm_provider': llm_response.model,
                        'grounded': grounding_result.is_grounded,
                        'confidence': grounding_result.confidence_score,
                        'top_k': top_k
                    }
                )
            
            # 9. Construir resposta final
            total_time = (time.time() - start_time) * 1000
            
            rag_response = RAGResponse(
                answer=processed_response.content,
                sources=processed_response.sources,
                confidence_score=grounding_result.confidence_score,
                response_time_ms=total_time,
                is_grounded=grounding_result.is_grounded,
                query_id=query_id or "unknown",
                metadata={
                    'search_results_count': len(search_results),
                    'reranked_count': len(reranked_results),
                    'llm_provider': llm_response.model,
                    'llm_usage': llm_response.usage,
                    'grounding_metadata': grounding_result.metadata,
                    'quality_score': processed_response.quality_score,
                    'output_format': output_format.value
                }
            )
            
            logger.info(f"âœ… Query processada em {total_time:.0f}ms - Grounded: {grounding_result.is_grounded}")
            return rag_response
            
        except Exception as e:
            logger.error(f"âŒ Erro durante processamento da query: {e}")
            return self._create_error_response(question, str(e), start_time)
    
    def _create_empty_response(self, question: str, start_time: float) -> RAGResponse:
        """Cria resposta vazia quando nÃ£o hÃ¡ resultados"""
        return RAGResponse(
            answer="Desculpe, nÃ£o consegui encontrar informaÃ§Ãµes relevantes para responder sua pergunta nos documentos disponÃ­veis.",
            sources=[],
            confidence_score=0.0,
            response_time_ms=(time.time() - start_time) * 1000,
            is_grounded=False,
            query_id="empty",
            metadata={'error': 'no_results_found'}
        )
    
    def _create_error_response(self, question: str, error: str, start_time: float) -> RAGResponse:
        """Cria resposta de erro"""
        return RAGResponse(
            answer=f"Ocorreu um erro ao processar sua pergunta: {error}",
            sources=[],
            confidence_score=0.0,
            response_time_ms=(time.time() - start_time) * 1000,
            is_grounded=False,
            query_id="error",
            metadata={'error': error}
        )
    
    def log_user_feedback(
        self, 
        query_id: str, 
        feedback_type: FeedbackType,
        result_id: str = None
    ):
        """
        Log de feedback do usuÃ¡rio
        
        Args:
            query_id: ID da query
            feedback_type: Tipo de feedback
            result_id: ID do resultado (opcional)
        """
        if self.telemetry_collector:
            self.telemetry_collector.log_feedback(feedback_type, result_id, query_id)
    
    def log_result_click(
        self,
        result_id: str,
        position: int,
        query: str = None
    ):
        """
        Log de clique em resultado
        
        Args:
            result_id: ID do resultado clicado
            position: PosiÃ§Ã£o do resultado (0-indexed)
            query: Query original (opcional)
        """
        if self.telemetry_collector:
            self.telemetry_collector.log_click(result_id, position, query)
    
    def optimize_performance(self) -> bool:
        """
        Executa otimizaÃ§Ã£o automÃ¡tica baseada em telemetria
        
        Returns:
            True se otimizaÃ§Ã£o foi aplicada
        """
        if not self.learning_engine:
            logger.warning("Learning engine nÃ£o estÃ¡ habilitado")
            return False
        
        return self.learning_engine.auto_optimize()
    
    def get_analytics(self, days: int = 7) -> Dict[str, Any]:
        """
        ObtÃ©m analytics do sistema
        
        Args:
            days: NÃºmero de dias para anÃ¡lise
            
        Returns:
            Dict com mÃ©tricas e anÃ¡lises
        """
        if not self.telemetry_collector:
            return {"error": "Telemetria nÃ£o habilitada"}
        
        import importlib
        telemetry_module = importlib.import_module('telemetry-learning.main')
        AnalyticsEngine = telemetry_module.AnalyticsEngine
        analytics = AnalyticsEngine()
        
        return {
            'performance_metrics': analytics.get_performance_metrics(days),
            'query_analytics': analytics.get_query_analytics(days=days),
            'system_status': self._get_system_status()
        }
    
    def _get_system_status(self) -> Dict[str, Any]:
        """ObtÃ©m status dos componentes do sistema"""
        status = {
            'index_available': True,  # TODO: implementar verificaÃ§Ã£o real
            'llm_providers': self.llm_manager.get_available_providers(),
            'telemetry_enabled': self.enable_telemetry,
            'current_session': self.telemetry_collector.current_session_id if self.telemetry_collector else None
        }
        return status


def main():
    """FunÃ§Ã£o principal para demonstraÃ§Ã£o"""
    
    print("ðŸš€ Iniciando Sistema RAG Completo")
    print("=" * 60)
    
    # Inicializar sistema
    rag = RAGSystem(enable_telemetry=True)
    
    # Verificar se hÃ¡ documentos indexados, senÃ£o criar alguns de exemplo
    sample_json = Path("sample_documents.json")
    
    if not sample_json.exists():
        print("ðŸ“„ Criando documentos de exemplo...")
        sample_docs = [
            {
                "title": "IntroduÃ§Ã£o ao Python",
                "content": "Python Ã© uma linguagem de programaÃ§Ã£o de alto nÃ­vel, interpretada e de propÃ³sito geral. Foi criada por Guido van Rossum e lanÃ§ada em 1991. Python Ã© conhecida por sua sintaxe clara e legÃ­vel, o que a torna uma excelente escolha para iniciantes em programaÃ§Ã£o. A linguagem suporta mÃºltiplos paradigmas de programaÃ§Ã£o, incluindo programaÃ§Ã£o orientada a objetos, programaÃ§Ã£o procedural e programaÃ§Ã£o funcional.",
                "category": "programming",
                "difficulty": "beginner"
            },
            {
                "title": "Machine Learning com Python",
                "content": "Machine Learning Ã© um subcampo da inteligÃªncia artificial que permite que computadores aprendam e melhorem automaticamente a partir da experiÃªncia sem serem explicitamente programados. Python oferece vÃ¡rias bibliotecas poderosas para ML, incluindo scikit-learn, TensorFlow e PyTorch. Estas ferramentas facilitam a implementaÃ§Ã£o de algoritmos de aprendizado supervisionado, nÃ£o supervisionado e por reforÃ§o.",
                "category": "ai",
                "difficulty": "intermediate"
            },
            {
                "title": "Desenvolvimento Web com Python",
                "content": "Python Ã© amplamente usado no desenvolvimento web atravÃ©s de frameworks como Django e Flask. Django Ã© um framework web de alto nÃ­vel que encoraja o desenvolvimento rÃ¡pido e design limpo e pragmÃ¡tico. Flask Ã© um micro-framework que fornece as ferramentas bÃ¡sicas para construir aplicaÃ§Ãµes web. Ambos sÃ£o excelentes opÃ§Ãµes para criar desde simples sites atÃ© aplicaÃ§Ãµes web complexas.",
                "category": "web",
                "difficulty": "intermediate"
            },
            {
                "title": "CiÃªncia de Dados com Python",
                "content": "Python se tornou a linguagem preferida para ciÃªncia de dados devido Ã  sua simplicidade e ao ecossistema rico de bibliotecas especializadas. Pandas Ã© usado para manipulaÃ§Ã£o e anÃ¡lise de dados, NumPy para computaÃ§Ã£o numÃ©rica, Matplotlib e Seaborn para visualizaÃ§Ã£o de dados, e Jupyter Notebooks fornece um ambiente interativo para anÃ¡lise exploratÃ³ria de dados.",
                "category": "data_science", 
                "difficulty": "intermediate"
            }
        ]
        
        with open(sample_json, 'w', encoding='utf-8') as f:
            json.dump(sample_docs, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… Arquivo criado: {sample_json}")
    
    # Indexar documentos
    print("ðŸ“š Indexando documentos...")
    success = rag.index_documents(str(sample_json))
    
    if not success:
        print("âŒ Falha na indexaÃ§Ã£o. Verifique os logs.")
        return
    
    print("âœ… Documentos indexados com sucesso!")
    print()
    
    # Exemplos de queries
    queries = [
        "O que Ã© Python?",
        "Como fazer machine learning com Python?",
        "Quais frameworks web Python?",
        "Python para ciÃªncia de dados"
    ]
    
    for i, query in enumerate(queries, 1):
        print(f"ðŸ” Query {i}: {query}")
        print("-" * 40)
        
        # Executar query
        response = rag.query(
            query, 
            top_k=3,
            output_format=OutputFormat.MARKDOWN,
            include_sources=True
        )
        
        # Mostrar resultado
        print(f"â±ï¸  Tempo: {response.response_time_ms:.0f}ms")
        print(f"ðŸŽ¯ ConfianÃ§a: {response.confidence_score:.3f}")
        print(f"âœ… Grounded: {response.is_grounded}")
        print()
        
        print("ðŸ“ Resposta:")
        print(response.answer)
        print()
        
        # Simular feedback (apenas para demonstraÃ§Ã£o)
        if response.confidence_score > 0.5:
            rag.log_user_feedback(response.query_id, FeedbackType.THUMBS_UP)
        
        print("=" * 60)
        print()
    
    # Mostrar analytics
    print("ðŸ“Š Analytics do Sistema:")
    analytics = rag.get_analytics(days=1)
    
    if 'performance_metrics' in analytics:
        metrics = analytics['performance_metrics']
        print(f"Total de queries: {metrics.get('total_queries', 0)}")
        print(f"Total de cliques: {metrics.get('total_clicks', 0)}")
        print(f"CTR global: {metrics.get('global_ctr', 0):.2%}")
        print(f"Tempo mÃ©dio: {metrics.get('avg_response_time', 0):.0f}ms")
    
    print()
    
    # Testar otimizaÃ§Ã£o
    print("ðŸ§  Testando otimizaÃ§Ã£o automÃ¡tica:")
    optimized = rag.optimize_performance()
    print(f"OtimizaÃ§Ã£o aplicada: {'Sim' if optimized else 'NÃ£o'}")
    
    print()
    print("ðŸŽ‰ DemonstraÃ§Ã£o completa!")


if __name__ == "__main__":
    main()